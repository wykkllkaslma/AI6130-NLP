from openai import OpenAI
from scripts.retriever import retrieve

# Initialize OpenAI client with Deepseek API endpoint
client = OpenAI(api_key='sk-975373c306f14fd28a5dca9cbf7576a6', base_url='https://api.deepseek.com')

def answer(query):
    """
    Process user query and generate answer using LLM
    
    Args:
        query (str): The user's question
    
    Returns:
        tuple: (generated_answer, list_of_reference_urls)
            - generated_answer: str, The answer generated by the LLM
            - list_of_reference_urls: list, URLs of reference materials
    """
    # Retrieve relevant contexts using retriever module
    ctx = retrieve(query)
    
    # Format retrieved contexts into numbered list
    context_text = "\n\n".join([f"[{i+1}] {c[0][0]}" for i, c in enumerate(ctx)])
    
    # Extract reference URLs from contexts
    refs = [c[0][1]["url"] for c in ctx]
    
    # Construct prompt template with context and query
    prompt = f"""You are a medical assistant. Answer based only on context:

{context_text}

Question: {query}

If the question is not in English. Your should take the translation of context into account.
And your answer should be based on the language of Question. 

Provide references as [1], [2] matching context.
"""
    # Call LLM to generate response
    resp = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
    )
    
    # Return generated answer and reference URLs
    return resp.choices[0].message.content, refs